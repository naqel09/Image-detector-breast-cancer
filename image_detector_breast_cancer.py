# -*- coding: utf-8 -*-
"""image detector breast cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QV68lMYdl78m-55ZSZxt-hbmmDu-j2EE
"""

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download 'hayder17/breast-cancer-detection'

!unzip breast-cancer-detection.zip

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from datasets import load_dataset

# Pastikan plot matplotlib ditampilkan inline di Jupyter Notebook
# %matplotlib inline

# Menonaktifkan beberapa peringatan TensorFlow yang kurang relevan
tf.get_logger().setLevel('ERROR')

print("INFO: Pustaka berhasil diimpor.")

# -- Parameter Konfigurasi --
IMG_WIDTH, IMG_HEIGHT = 128, 128  # Ukuran gambar yang akan digunakan
BATCH_SIZE = 32                    # Jumlah sampel per batch
EPOCHS = 50                        # Jumlah epoch maksimal untuk pelatihan
VAL_SPLIT = 0.2                    # Persentase data untuk validasi
PATIENCE = 10                      # Jumlah epoch tanpa peningkatan sebelum early stopping

print(f"INFO: Parameter Konfigurasi: IMG_SIZE=({IMG_WIDTH},{IMG_HEIGHT}), BATCH_SIZE={BATCH_SIZE}, EPOCHS={EPOCHS}")

# -- 1. Pengunduhan dan Pemuatan Dataset --
# The previous steps (kaggle download and unzip) should have already been run
# and the data should be available in the current directory.
DATA_DIR = './' # Assuming the zip was unzipped in the current directory

# Use tensorflow's image_dataset_from_directory to load the data
# It expects a directory structure like DATA_DIR/train/class_0/... DATA_DIR/train/class_1/... etc.

print(f"INFO: Loading dataset from local directory: {DATA_DIR}")

try:
    # Assuming the unzipped data has 'train' and 'test' directories at the root
    train_data_dir = os.path.join(DATA_DIR, 'train')
    test_data_dir = os.path.join(DATA_DIR, 'test')

    if not os.path.exists(train_data_dir):
        raise FileNotFoundError(f"Training data directory not found at {train_data_dir}")
    if not os.path.exists(test_data_dir):
         # The test directory might not exist depending on the dataset structure,
         # handle this based on your actual unzipped files.
         # For this dataset, it seems there are 'train' and 'test' directories.
         # If 'test' doesn't exist, you might need to split 'train' further.
         print(f"WARNING: Test data directory not found at {test_data_dir}. Proceeding with train only.")
         test_data_dir = None # Set to None if not available


    # Load training data, splitting off a validation set
    train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(
        train_data_dir,
        labels='inferred',
        label_mode='binary', # Assuming binary classification (0 or 1)
        image_size=(IMG_WIDTH, IMG_HEIGHT),
        interpolation='nearest',
        batch_size=BATCH_SIZE,
        shuffle=True,
        seed=42, # for reproducibility
        validation_split=VAL_SPLIT,
        subset='both' # Get both training and validation subsets
    )

    test_ds = None
    if test_data_dir and os.path.exists(test_data_dir):
        # Load test data
        test_ds = tf.keras.utils.image_dataset_from_directory(
            test_data_dir,
            labels='inferred',
            label_mode='binary', # Assuming binary classification (0 or 1)
            image_size=(IMG_WIDTH, IMG_HEIGHT),
            interpolation='nearest',
            batch_size=BATCH_SIZE,
            shuffle=False, # No need to shuffle test data
            seed=42 # for reproducibility
        )

    print("INFO: Dataset berhasil dimuat menggunakan tf.keras.utils.image_dataset_from_directory.")
    print(f"INFO: Jumlah sampel pelatihan: {len(train_ds) * BATCH_SIZE}")
    print(f"INFO: Jumlah sampel validasi: {len(val_ds) * BATCH_SIZE}")
    if test_ds:
        print(f"INFO: Jumlah sampel pengujian: {len(test_ds) * BATCH_SIZE}")
    print(f"INFO: Nama kelas: {train_ds.class_names}")

except FileNotFoundError as fnf_error:
    print(f"ERROR: Direktori data tidak ditemukan. Pastikan Anda telah mengunduh dan mengekstrak dataset dengan benar. Detail: {fnf_error}")
    raise # Rethrow the error to stop execution

except Exception as e:
    print(f"ERROR: Gagal memuat dataset dari direktori lokal. Detail: {e}")
    # Hentikan eksekusi jika dataset gagal dimuat
    raise

# -- 2. Pra-pemrosesan Data --
print("\nINFO: Memulai pra-pemrosesan data...")

# Ekstrak gambar dan label dari tf.data.Dataset objects
images = []
labels = []

# Iterate over the train_ds dataset to extract images and labels
# The elements of tf.data.Dataset loaded with image_dataset_from_directory are tuples (image, label)
print("INFO: Extracting data from train_ds...")
for image_batch, label_batch in train_ds:
    # image_batch is a tensor of shape (batch_size, height, width, channels)
    # label_batch is a tensor of shape (batch_size,)
    for img_tensor, label_tensor in zip(image_batch, label_batch):
        images.append(img_tensor.numpy()) # Convert tensor to numpy array
        labels.append(int(label_tensor.numpy())) # Convert tensor to numpy array and then to int

# Do the same for val_ds to get the full dataset before splitting
print("INFO: Extracting data from val_ds...")
for image_batch, label_batch in val_ds:
    for img_tensor, label_tensor in zip(image_batch, label_batch):
        images.append(img_tensor.numpy())
        labels.append(int(label_tensor.numpy()))

if not images:
    print("ERROR: Tidak ada gambar yang berhasil diproses dari tf.data.Dataset. Harap periksa pemuatan dataset.")
    # Hentikan eksekusi jika tidak ada gambar
    raise ValueError("Tidak ada gambar yang diproses.")

images = np.array(images)
labels = np.array(labels)

# Note: Normalization to [0, 1] range is often done *before* augmentation and splitting.
# tf.keras.utils.image_dataset_from_directory returns images as type float32 in range [0, 255].
# We need to normalize them to [0, 1] or [-1, 1] depending on the model's input requirements.
# Normalizing to [0, 1] is standard for ImageDataGenerator.
print("INFO: Normalizing image pixel values to [0, 1]...")
images = images / 255.0

# Cek jumlah kelas dan distribusi label
num_classes = len(np.unique(labels))
print(f"INFO: Jumlah gambar yang diproses: {len(images)}")
print(f"INFO: Jumlah label yang diproses: {len(labels)}")
print(f"INFO: Bentuk array gambar: {images.shape}")
print(f"INFO: Bentuk array label: {labels.shape}")
print(f"INFO: Jumlah kelas: {num_classes}")
print(f"INFO: Label unik: {np.unique(labels)}")
print(f"INFO: Distribusi label: {dict(zip(*np.unique(labels, return_counts=True)))}")

if num_classes < 2:
    print("ERROR: Dataset harus memiliki setidaknya 2 kelas untuk klasifikasi.")
    raise ValueError("Dataset tidak memiliki cukup kelas.")

# Membagi data menjadi data pelatihan dan data validasi
# We need to split the combined data again because image_dataset_from_directory's split
# might not be exactly the desired ratio and the manual extraction step recombines them.
# Alternatively, you could process train_ds and val_ds separately, but splitting after
# combining ensures the desired VAL_SPLIT ratio on the full available data.
print(f"INFO: Splitting data into training and validation sets with validation_split={VAL_SPLIT}...")
X_train, X_val, y_train, y_val = train_test_split(
    images, labels, test_size=VAL_SPLIT, random_state=42, stratify=labels
)

print(f"INFO: Jumlah data pelatihan setelah split: {len(X_train)}")
print(f"INFO: Jumlah data validasi setelah split: {len(X_val)}")

# Augmentasi Data
print("INFO: Setting up data augmentation...")
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

validation_datagen = ImageDataGenerator() # Only for ensuring consistency, normalization done earlier

# Fit the generators on the data
print("INFO: Fitting data generators...")
train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)
validation_generator = validation_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)

print("INFO: Pra-pemrosesan data selesai.")

# -- 3. Pembuatan Model CNN --
print("\nINFO: Membangun model CNN...")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(256, (3, 3), activation='relu', padding='same'), # Lapisan tambahan
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Flatten(),

    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),

    # Lapisan Output: 1 unit dengan 'sigmoid' untuk klasifikasi biner (0 atau 1)
    Dense(1, activation='sigmoid')
])

# Kompilasi Model
# Untuk klasifikasi biner dengan output sigmoid, gunakan 'binary_crossentropy'
loss_function = 'binary_crossentropy'
optimizer = Adam(learning_rate=0.0001) # Learning rate bisa disesuaikan

model.compile(optimizer=optimizer,
              loss=loss_function,
              metrics=['accuracy'])

model.summary()

# -- 4. Pelatihan Model --
print("\nINFO: Memulai pelatihan model...")

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=PATIENCE // 2, min_lr=1e-6, verbose=1)

history = model.fit(
    train_generator,
    steps_per_epoch=max(1, len(X_train) // BATCH_SIZE), # Pastikan steps_per_epoch minimal 1
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=max(1, len(X_val) // BATCH_SIZE), # Pastikan validation_steps minimal 1
    callbacks=[early_stopping, reduce_lr]
)

print("INFO: Pelatihan model selesai.")

# -- 5. Evaluasi Model --
print("\nINFO: Mengevaluasi model...")

# Evaluasi pada data validasi penuh
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"\nLoss Validasi Akhir: {val_loss:.4f}")
print(f"Akurasi Validasi Akhir: {val_accuracy*100:.2f}%")

# Plotting hasil pelatihan (Akurasi dan Loss)
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss_hist = history.history['val_loss']

epochs_range = range(len(acc))

plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Akurasi Training')
plt.plot(epochs_range, val_acc, label='Akurasi Validasi')
plt.legend(loc='lower right')
plt.title('Akurasi Training dan Validasi')
plt.xlabel('Epoch')
plt.ylabel('Akurasi')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Loss Training')
plt.plot(epochs_range, val_loss_hist, label='Loss Validasi')
plt.legend(loc='upper right')
plt.title('Loss Training dan Validasi')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.tight_layout()
plt.show()

# -- 7. Prediksi pada Gambar Baru (Contoh) --

# Definisikan nama kelas sesuai dengan dataset Anda
# Untuk dataset ini, label 0 biasanya 'benign' (jinak) dan 1 'malignant' (ganas)
# Anda bisa memverifikasi ini dari train_ds.class_names

class_names = {
    0: 'Tidak Kanker',
    1: 'Kanker (Ganas)'
}
print(f"INFO: Nama kelas yang akan digunakan untuk inferensi: {class_names}")

# Path ke model yang disimpan (ganti dengan path Anda jika berbeda)
# model_path = "saved_models/breast_cancer_classifier_model.keras"
# model_path = "breast_cancer_classifier_model.keras" # Jika disimpan di root direktori notebook

# Cek apakah variabel 'model' sudah ada (dari pelatihan sebelumnya di sesi yang sama)
try:
    model # Cek apakah model sudah terdefinisi
    print("INFO: Model sudah ada di memori dari sesi pelatihan saat ini.")
except NameError:
    print(f"INFO: Model belum ada di memori. Mencoba memuat dari file...")
    model_path = "breast_cancer_classifier_model.keras" # <--- SESUAIKAN PATH INI JIKA PERLU
    if os.path.exists(model_path):
        model = tf.keras.models.load_model(model_path)
        print(f"INFO: Model berhasil dimuat dari {model_path}")
        # model.summary() # Opsional: tampilkan summary untuk verifikasi
    else:
        print(f"ERROR: File model tidak ditemukan di {model_path}. Pastikan path sudah benar atau latih model terlebih dahulu.")
        # Anda bisa menghentikan eksekusi di sini jika model tidak bisa dimuat
        # raise FileNotFoundError(f"Model tidak ditemukan di {model_path}")

def predict_single_image_kanker(image_path, model_loaded, img_width, img_height, class_names_map):
    try:
        img = Image.open(image_path).convert('RGB') # Pastikan konversi ke RGB
        img_original_size = img.size

        # Pra-pemrosesan gambar
        img_resized = img.resize((img_width, img_height))
        img_array = np.array(img_resized) / 255.0  # Normalisasi
        img_batch = np.expand_dims(img_array, axis=0) # Tambah dimensi batch

        # Lakukan prediksi
        # Output model sigmoid adalah probabilitas untuk kelas positif (kelas 1)
        prediction_prob_kanker = model_loaded.predict(img_batch)[0][0]

        # Tentukan kelas berdasarkan ambang batas 0.5
        if prediction_prob_kanker > 0.5:
            predicted_class_index = 1 # Kanker (Ganas)
            confidence = prediction_prob_kanker
        else:
            predicted_class_index = 0 # Tidak Kanker (Jinak)
            confidence = 1 - prediction_prob_kanker

        # Dapatkan label nama kelas yang diprediksi
        predicted_label = class_names_map.get(predicted_class_index, "Label Tidak Diketahui")

        # Tampilkan hasil
        print(f"\n--- Hasil Prediksi untuk gambar: {os.path.basename(image_path)} ---")
        print(f"Probabilitas(untuk kelas 'Kanker'): {prediction_prob_kanker:.4f}")
        print(f"Prediksi Label: {predicted_label}")
        print(f"Akurasi Prediksi (Keyakinan): {confidence*100:.2f}%")

        # Tampilkan gambar dengan prediksinya
        plt.figure(figsize=(6,6))
        # plt.imshow(img_resized) # Jika ingin menampilkan gambar yang diresize
        plt.imshow(img) # Tampilkan gambar asli untuk kejelasan
        plt.title(f"Prediksi: {predicted_label}\nAkurasi Prediksi: {confidence*100:.2f}%", fontsize=10)
        plt.axis('off')
        plt.show()

        return predicted_label, confidence

    except FileNotFoundError:
        print(f"ERROR: File gambar tidak ditemukan di {image_path}")
        return None, None
    except Exception as e:
        print(f"ERROR: Terjadi kesalahan saat memproses gambar {image_path}: {e}")
        return None, None

print("INFO: Fungsi predict_single_image_kanker siap digunakan.")

"""Screenshot 2025-05-30 031908.png"""

# -- Contoh Penggunaan Inferensi --

# Pastikan model sudah ada di memori (baik dari pelatihan atau sudah dimuat)
if 'model' not in locals() and 'model' not in globals():
    print("ERROR: Variabel 'model' tidak terdefinisi. Latih atau muat model terlebih dahulu.")
else:
    # GANTI DENGAN PATH KE GAMBAR YANG INGIN ANDA UJI
    # Unggah gambar ke direktori kerja Jupyter Notebook Anda atau berikan path lengkapnya.
    # Contoh:
    path_gambar_uji_1 = "nama_file_gambar_anda_1.jpg"  # <--- GANTI INI
    path_gambar_uji_2 = "Screenshot 2025-05-30 031908.png"  # <--- GANTI INI

    daftar_gambar_untuk_diuji = []

    if os.path.exists(path_gambar_uji_1):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_1)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_1}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    if os.path.exists(path_gambar_uji_2):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_2)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_2}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    # Tambahkan path gambar lain jika perlu
    # daftar_gambar_untuk_diuji.append("path/lain/ke/gambar.jpeg")

    if not daftar_gambar_untuk_diuji:
        print("\nINFO: Tidak ada gambar uji yang valid ditemukan.")
        print("Silakan unggah gambar ke direktori notebook Anda dan perbarui variabel 'path_gambar_uji_...' di atas,")
        print("kemudian jalankan sel ini lagi.")
        print("Contoh: Jika Anda mengunggah 'breast_image.png', maka tulis: path_gambar_uji_1 = 'breast_image.png'")
    else:
        print(f"\nINFO: Menjalankan inferensi untuk {len(daftar_gambar_untuk_diuji)} gambar...")
        for img_path in daftar_gambar_untuk_diuji:
            # Menggunakan fungsi yang telah disesuaikan
            label_prediksi, skor_keyakinan = predict_single_image_kanker(
                img_path,
                model,
                IMG_WIDTH,
                IMG_HEIGHT,
                class_names
            )
            # Anda bisa melakukan sesuatu dengan hasilnya di sini jika perlu
            if label_prediksi is not None:
                print(f"Ringkasan untuk {os.path.basename(img_path)}: Label = {label_prediksi}, Keyakinan = {skor_keyakinan*100:.2f}%")

# Pastikan model sudah ada di memori (baik dari pelatihan atau sudah dimuat)
if 'model' not in locals() and 'model' not in globals():
    print("ERROR: Variabel 'model' tidak terdefinisi. Latih atau muat model terlebih dahulu.")
else:
    # GANTI DENGAN PATH KE GAMBAR YANG INGIN ANDA UJI
    # Unggah gambar ke direktori kerja Jupyter Notebook Anda atau berikan path lengkapnya.
    # Contoh:
    path_gambar_uji_1 = "105_1934323665_png.rf.a1e70bb0747c86f17a76a13894e8e191.jpg"  # <--- GANTI INI
    path_gambar_uji_2 = "ganas.png"  # <--- GANTI INI

    daftar_gambar_untuk_diuji = []

    if os.path.exists(path_gambar_uji_1):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_1)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_1}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    if os.path.exists(path_gambar_uji_2):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_2)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_2}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    # Tambahkan path gambar lain jika perlu
    # daftar_gambar_untuk_diuji.append("path/lain/ke/gambar.jpeg")

    if not daftar_gambar_untuk_diuji:
        print("\nINFO: Tidak ada gambar uji yang valid ditemukan.")
        print("Silakan unggah gambar ke direktori notebook Anda dan perbarui variabel 'path_gambar_uji_...' di atas,")
        print("kemudian jalankan sel ini lagi.")
        print("Contoh: Jika Anda mengunggah 'breast_image.png', maka tulis: path_gambar_uji_1 = 'breast_image.png'")
    else:
        print(f"\nINFO: Menjalankan inferensi untuk {len(daftar_gambar_untuk_diuji)} gambar...")
        for img_path in daftar_gambar_untuk_diuji:
            # Menggunakan fungsi yang telah disesuaikan
            label_prediksi, skor_keyakinan = predict_single_image_kanker(
                img_path,
                model,
                IMG_WIDTH,
                IMG_HEIGHT,
                class_names
            )
            # Anda bisa melakukan sesuatu dengan hasilnya di sini jika perlu
            if label_prediksi is not None:
                print(f"Ringkasan untuk {os.path.basename(img_path)}: Label = {label_prediksi}, Keyakinan = {skor_keyakinan*100:.2f}%")

# Pastikan model sudah ada di memori (baik dari pelatihan atau sudah dimuat)
if 'model' not in locals() and 'model' not in globals():
    print("ERROR: Variabel 'model' tidak terdefinisi. Latih atau muat model terlebih dahulu.")
else:
    # GANTI DENGAN PATH KE GAMBAR YANG INGIN ANDA UJI
    # Unggah gambar ke direktori kerja Jupyter Notebook Anda atau berikan path lengkapnya.
    # Contoh:
    path_gambar_uji_1 = "test/0/105_1934323665_png.rf.a1e70bb0747c86f17a76a13894e8e191.jpg"  # <--- GANTI INI
    path_gambar_uji_2 = "contoh.png"  # <--- GANTI INI

    daftar_gambar_untuk_diuji = []

    if os.path.exists(path_gambar_uji_1):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_1)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_1}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    if os.path.exists(path_gambar_uji_2):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_2)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_2}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    # Tambahkan path gambar lain jika perlu
    # daftar_gambar_untuk_diuji.append("path/lain/ke/gambar.jpeg")

    if not daftar_gambar_untuk_diuji:
        print("\nINFO: Tidak ada gambar uji yang valid ditemukan.")
        print("Silakan unggah gambar ke direktori notebook Anda dan perbarui variabel 'path_gambar_uji_...' di atas,")
        print("kemudian jalankan sel ini lagi.")
        print("Contoh: Jika Anda mengunggah 'breast_image.png', maka tulis: path_gambar_uji_1 = 'breast_image.png'")
    else:
        print(f"\nINFO: Menjalankan inferensi untuk {len(daftar_gambar_untuk_diuji)} gambar...")
        for img_path in daftar_gambar_untuk_diuji:
            # Menggunakan fungsi yang telah disesuaikan
            label_prediksi, skor_keyakinan = predict_single_image_kanker(
                img_path,
                model,
                IMG_WIDTH,
                IMG_HEIGHT,
                class_names
            )
            # Anda bisa melakukan sesuatu dengan hasilnya di sini jika perlu
            if label_prediksi is not None:
                print(f"Ringkasan untuk {os.path.basename(img_path)}: Label = {label_prediksi}, Keyakinan = {skor_keyakinan*100:.2f}%")

"""1588_1603972171_png.rf.29f8eb427de2e92c2222298b7b497ad0.jpg"""

# Pastikan model sudah ada di memori (baik dari pelatihan atau sudah dimuat)
if 'model' not in locals() and 'model' not in globals():
    print("ERROR: Variabel 'model' tidak terdefinisi. Latih atau muat model terlebih dahulu.")
else:
    # GANTI DENGAN PATH KE GAMBAR YANG INGIN ANDA UJI
    # Unggah gambar ke direktori kerja Jupyter Notebook Anda atau berikan path lengkapnya.
    # Contoh:
    path_gambar_uji_1 = "test/0/2028_2082854771_png.rf.c48712e6c2dda9a2315a0dfb713adfee.jpg"  # <--- GANTI INI
    path_gambar_uji_2 = "contoh.png"  # <--- GANTI INI

    daftar_gambar_untuk_diuji = []

    if os.path.exists(path_gambar_uji_1):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_1)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_1}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    if os.path.exists(path_gambar_uji_2):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_2)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_2}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    # Tambahkan path gambar lain jika perlu
    # daftar_gambar_untuk_diuji.append("path/lain/ke/gambar.jpeg")

    if not daftar_gambar_untuk_diuji:
        print("\nINFO: Tidak ada gambar uji yang valid ditemukan.")
        print("Silakan unggah gambar ke direktori notebook Anda dan perbarui variabel 'path_gambar_uji_...' di atas,")
        print("kemudian jalankan sel ini lagi.")
        print("Contoh: Jika Anda mengunggah 'breast_image.png', maka tulis: path_gambar_uji_1 = 'breast_image.png'")
    else:
        print(f"\nINFO: Menjalankan inferensi untuk {len(daftar_gambar_untuk_diuji)} gambar...")
        for img_path in daftar_gambar_untuk_diuji:
            # Menggunakan fungsi yang telah disesuaikan
            label_prediksi, skor_keyakinan = predict_single_image_kanker(
                img_path,
                model,
                IMG_WIDTH,
                IMG_HEIGHT,
                class_names
            )
            # Anda bisa melakukan sesuatu dengan hasilnya di sini jika perlu
            if label_prediksi is not None:
                print(f"Ringkasan untuk {os.path.basename(img_path)}: Label = {label_prediksi}, Keyakinan = {skor_keyakinan*100:.2f}%")

"""1025_773597682_png.rf.10eef608772845290c0ed1c5dc80c3ac.jpg"""

# Pastikan model sudah ada di memori (baik dari pelatihan atau sudah dimuat)
if 'model' not in locals() and 'model' not in globals():
    print("ERROR: Variabel 'model' tidak terdefinisi. Latih atau muat model terlebih dahulu.")
else:
    # GANTI DENGAN PATH KE GAMBAR YANG INGIN ANDA UJI
    # Unggah gambar ke direktori kerja Jupyter Notebook Anda atau berikan path lengkapnya.
    # Contoh:
    path_gambar_uji_1 = "test/1/16703_87510051_png.rf.c4b59cce87ffe7abb2db9fa1ac5d8431.jpg"  # <--- GANTI INI
    path_gambar_uji_2 = "contoh.png"  # <--- GANTI INI

    daftar_gambar_untuk_diuji = []

    if os.path.exists(path_gambar_uji_1):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_1)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_1}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    if os.path.exists(path_gambar_uji_2):
        daftar_gambar_untuk_diuji.append(path_gambar_uji_2)
    else:
        print(f"WARNING: Gambar uji '{path_gambar_uji_2}' tidak ditemukan. Silakan unggah atau perbaiki path.")

    # Tambahkan path gambar lain jika perlu
    # daftar_gambar_untuk_diuji.append("path/lain/ke/gambar.jpeg")

    if not daftar_gambar_untuk_diuji:
        print("\nINFO: Tidak ada gambar uji yang valid ditemukan.")
        print("Silakan unggah gambar ke direktori notebook Anda dan perbarui variabel 'path_gambar_uji_...' di atas,")
        print("kemudian jalankan sel ini lagi.")
        print("Contoh: Jika Anda mengunggah 'breast_image.png', maka tulis: path_gambar_uji_1 = 'breast_image.png'")
    else:
        print(f"\nINFO: Menjalankan inferensi untuk {len(daftar_gambar_untuk_diuji)} gambar...")
        for img_path in daftar_gambar_untuk_diuji:
            # Menggunakan fungsi yang telah disesuaikan
            label_prediksi, skor_keyakinan = predict_single_image_kanker(
                img_path,
                model,
                IMG_WIDTH,
                IMG_HEIGHT,
                class_names
            )
            # Anda bisa melakukan sesuatu dengan hasilnya di sini jika perlu
            if label_prediksi is not None:
                print(f"Ringkasan untuk {os.path.basename(img_path)}: Label = {label_prediksi}, Keyakinan = {skor_keyakinan*100:.2f}%")